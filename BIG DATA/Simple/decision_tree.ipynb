{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, randn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 13:20:16 WARN Utils: Your hostname, sathvik-HP-EliteBook-x360-1030-G2 resolves to a loopback address: 127.0.1.1; using 192.168.0.108 instead (on interface wlp58s0)\n",
      "24/11/03 13:20:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/03 13:20:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Salary Prediction\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "|age|        workclass|  fnlwgt| education|education_num|     marital_status|        occupation|  relationship|  race|    sex|capital_gain|capital_loss|hours_per_week|native_country|income|\n",
      "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "| 39|        State-gov| 77516.0| Bachelors|         13.0|      Never-married|      Adm-clerical| Not-in-family| White|   Male|      2174.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 50| Self-emp-not-inc| 83311.0| Bachelors|         13.0| Married-civ-spouse|   Exec-managerial|       Husband| White|   Male|         0.0|         0.0|          13.0| United-States| <=50K|\n",
      "| 38|          Private|215646.0|   HS-grad|          9.0|           Divorced| Handlers-cleaners| Not-in-family| White|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 53|          Private|234721.0|      11th|          7.0| Married-civ-spouse| Handlers-cleaners|       Husband| Black|   Male|         0.0|         0.0|          40.0| United-States| <=50K|\n",
      "| 28|          Private|338409.0| Bachelors|         13.0| Married-civ-spouse|    Prof-specialty|          Wife| Black| Female|         0.0|         0.0|          40.0|          Cuba| <=50K|\n",
      "+---+-----------------+--------+----------+-------------+-------------------+------------------+--------------+------+-------+------------+------------+--------------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"../Data/adult.csv\", header=False, inferSchema=True)\n",
    "column_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\", \n",
    "                \"marital_status\", \"occupation\", \"relationship\", \"race\", \n",
    "                \"sex\", \"capital_gain\", \"capital_loss\", \"hours_per_week\", \n",
    "                \"native_country\", \"income\"]\n",
    "\n",
    "df = df.toDF(*column_names)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- workclass: string (nullable = true)\n",
      " |-- fnlwgt: double (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- education_num: double (nullable = true)\n",
      " |-- marital_status: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      " |-- race: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- capital_gain: double (nullable = true)\n",
      " |-- capital_loss: double (nullable = true)\n",
      " |-- hours_per_week: double (nullable = true)\n",
      " |-- native_country: string (nullable = true)\n",
      " |-- income: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/03 13:40:42 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|summary|               age|   workclass|            fnlwgt|    education|    education_num|marital_status|       occupation|relationship|               race|    sex|      capital_gain|    capital_loss|    hours_per_week|native_country|income|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "|  count|             32561|       32561|             32561|        32561|            32561|         32561|            32561|       32561|              32561|  32561|             32561|           32561|             32561|         32561| 32561|\n",
      "|   mean| 38.58164675532078|        NULL|189778.36651208502|         NULL| 10.0806793403151|          NULL|             NULL|        NULL|               NULL|   NULL|1077.6488437087312| 87.303829734959|40.437455852092995|          NULL|  NULL|\n",
      "| stddev|13.640432553581356|        NULL|105549.97769702227|         NULL|2.572720332067397|          NULL|             NULL|        NULL|               NULL|   NULL| 7385.292084840354|402.960218649002|12.347428681731838|          NULL|  NULL|\n",
      "|    min|                17|           ?|           12285.0|         10th|              1.0|      Divorced|                ?|     Husband| Amer-Indian-Eskimo| Female|               0.0|             0.0|               1.0|             ?| <=50K|\n",
      "|    max|                90| Without-pay|         1484705.0| Some-college|             16.0|       Widowed| Transport-moving|        Wife|              White|   Male|           99999.0|          4356.0|              99.0|    Yugoslavia|  >50K|\n",
      "+-------+------------------+------------+------------------+-------------+-----------------+--------------+-----------------+------------+-------------------+-------+------------------+----------------+------------------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.describe().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of observations in the dataframe: 32561\n",
      "Number of features in the dataset: 15\n",
      "Features: \n",
      "['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n"
     ]
    }
   ],
   "source": [
    "print(f\"The number of observations in the dataframe: {df.count()}\")\n",
    "print(f\"Number of features in the dataset: {len(df.columns)}\")\n",
    "print(\"Features: \")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "categorical_columns = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \n",
    "                \"relationship\", \"race\", \"sex\", \"native_country\", \"income\"]\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\") for column in categorical_columns]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=\n",
    "                            ['age', 'fnlwgt', 'education_num', 'capital_gain', 'capital_loss', 'hours_per_week'] + \n",
    "                            [col + \"_index\" for col in categorical_columns],\n",
    "              outputCol=\"features\")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "df_prepared = pipeline.fit(df_clean).transform(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "|            features|income_index|\n",
      "+--------------------+------------+\n",
      "|[39.0,77516.0,13....|         0.0|\n",
      "|(15,[0,1,2,5,6,7,...|         0.0|\n",
      "|(15,[0,1,2,5,8,9,...|         0.0|\n",
      "|(15,[0,1,2,5,7,9,...|         0.0|\n",
      "|[28.0,338409.0,13...|         0.0|\n",
      "+--------------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prepared.select(\"features\", \"income_index\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------+\n",
      "|            features|income_index|prediction|\n",
      "+--------------------+------------+----------+\n",
      "|[17.0,41643.0,7.0...|         0.0|       0.0|\n",
      "|[17.0,64785.0,6.0...|         0.0|       0.0|\n",
      "|[17.0,80077.0,7.0...|         0.0|       0.0|\n",
      "|[17.0,104025.0,7....|         0.0|       0.0|\n",
      "|[17.0,139183.0,6....|         0.0|       0.0|\n",
      "+--------------------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data, test_data = df_prepared.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"income_index\", featuresCol=\"features\", maxBins=45)\n",
    "dt_model = dt.fit(train_data)\n",
    "\n",
    "predictions = dt_model.transform(test_data)\n",
    "\n",
    "predictions.select(\"features\", \"income_index\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "precision = precision_evaluator.evaluate(predictions)\n",
    "\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"income_index\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "recall = recall_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
