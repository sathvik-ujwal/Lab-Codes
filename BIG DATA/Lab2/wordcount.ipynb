{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"wordcount\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef clean_and_split(line):\\n  if isinstance(line, str):\\n    return line.split()\\n  else:\\n    return []\\n    '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def clean_and_split(line):\n",
    "  if isinstance(line, str):\n",
    "    return line.split()\n",
    "  else:\n",
    "    return []\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntextfile = spark.read.text(\"/home/sathvik/Documents/pyspark/Data/text.txt\").rdd\\nwords_rdd = textfile.flatMap(clean_and_split)\\nword_count_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\\nword_count_rdd\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "textfile = spark.read.text(\"/home/sathvik/Documents/pyspark/Data/text.txt\").rdd\n",
    "words_rdd = textfile.flatMap(clean_and_split)\n",
    "word_count_rdd = words_rdd.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\n",
    "word_count_rdd\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(value=\"vent streaming is the digital equivalent of the human body's central nervous system. It is the technological foundation for the 'always-on' world where businesses are increasingly software-defined and automated, and where the user of software is more software.\"),\n",
       " Row(value=''),\n",
       " Row(value='Technically speaking, event streaming is the practice of capturing data in real-time from event sources like databases, sensors, mobile devices, cloud services, and software applications in the form of streams of events; storing these event streams durably for later retrieval; manipulating, processing, and reacting to the event streams in real-time as well as retrospectively; and routing the event streams to different destination technologies as needed. Event streaming thus ensures a continuous flow and interpretation of data so that the right information is at the right place, at the right time. '),\n",
       " Row(value='vent streaming is applied to a wide variety of use cases across a plethora of industries and organizations. Its many examples include:'),\n",
       " Row(value='')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"/home/sathvik/Documents/pyspark/Data/text2.txt\"\n",
    "df = spark.read.text(file_path)\n",
    "df.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|     vent|\n",
      "|streaming|\n",
      "|       is|\n",
      "|      the|\n",
      "|  digital|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_df = df.select(F.explode(F.split(F.col(\"value\"), \" \")) \\\n",
    "                     .alias(\"word\"))\n",
    "words_df = words_df.withColumn(\"word\", F.lower(F.col(\"word\")))\n",
    "words_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   word|count|\n",
      "+-------+-----+\n",
      "| travel|    1|\n",
      "|   some|    2|\n",
      "|  those|    2|\n",
      "|routing|    1|\n",
      "| import|    1|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "word_count_df = words_df.groupBy(\"word\").count()\n",
    "word_count_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
